<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Astronave con SLAM</title>
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.rawgit.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.min.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
</head>
<body style="margin: 0; overflow: hidden;">

<!-- Scena AR.js -->
<a-scene embedded arjs 
         renderer="colorManagement: true, physicallyCorrectLights" 
         vr-mode-ui="enabled: false" 
         device-orientation-permission-ui="enabled: false">
    
  <a-assets>
      <a-asset-item id="astro" src="ASTRONAVE.glb"></a-asset-item>
  </a-assets>

  <!-- Modello 3D della astronave -->
  <a-entity id="astronave" position="0 0 0" gltf-model="#astro" scale="1 1 1"></a-entity>

  <!-- Fotocamera per la scena AR -->
  <a-camera position="0 0 0" look-controls="enabled: false" cursor="fuse: false; rayOrigin: mouse;" raycaster="near: 10; far: 10000; objects: .clickable"></a-camera>

</a-scene>

<!-- Video e canvas per OpenCV.js -->
<video id="video" width="640" height="480" autoplay></video>
<canvas id="canvasOutput" width="640" height="480"></canvas>

<script type="text/javascript">
  function startVideoProcessing() {
    const video = document.getElementById('video');
    const canvasOutput = document.getElementById('canvasOutput');
    const ctx = canvasOutput.getContext('2d');

    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
      video.srcObject = stream;
    });

    video.addEventListener('play', () => {
      // Assicurati che le dimensioni del video siano corrette
      const width = video.videoWidth;
      const height = video.videoHeight;

      // Verifica il formato del video
      let type = cv.CV_8UC4;
      const isRGB = false; // Assumiamo che il video sia RGBA, cambia a true se il video è RGB

      if (isRGB) {
        type = cv.CV_8UC3; // Cambia a 3 canali se il video è in RGB
      }

      const src = new cv.Mat(height, width, type);
      const gray = new cv.Mat(height, width, cv.CV_8UC1);
      const prevGray = new cv.Mat(height, width, cv.CV_8UC1);
      const cap = new cv.VideoCapture(video);

      // Inizializza ORB e matcher
      const detector = new cv.ORB();
      const matcher = new cv.BFMatcher(cv.NORM_HAMMING, true);
      let keypointsPrev = new cv.KeyPointVector();
      let descriptorsPrev = new cv.Mat();

      // Legge il primo frame per l'inizializzazione
      cap.read(src);
      cv.cvtColor(src, prevGray, cv.COLOR_RGBA2GRAY); // Cambia a COLOR_RGB2GRAY se il video è RGB
      detector.detectAndCompute(prevGray, new cv.Mat(), keypointsPrev, descriptorsPrev);

      function processVideo() {
        cap.read(src);
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY); // Cambia a COLOR_RGB2GRAY se il video è RGB

        const keypointsCurr = new cv.KeyPointVector();
        const descriptorsCurr = new cv.Mat();
        detector.detectAndCompute(gray, new cv.Mat(), keypointsCurr, descriptorsCurr);

        const matches = new cv.DMatchVector();
        matcher.match(descriptorsPrev, descriptorsCurr, matches);

        const matchedPoints = [];
        for (let i = 0; i < matches.size(); i++) {
          const match = matches.get(i);
          const prevPoint = keypointsPrev.get(match.queryIdx).pt;
          const currPoint = keypointsCurr.get(match.trainIdx).pt;
          matchedPoints.push({ prev: prevPoint, curr: currPoint });
        }

        console.log(`Number of matched points: ${matchedPoints.length}`);

        if (matchedPoints.length > 5) {
          const avgX = matchedPoints.reduce((sum, p) => sum + p.curr.x, 0) / matchedPoints.length;
          const avgY = matchedPoints.reduce((sum, p) => sum + p.curr.y, 0) / matchedPoints.length;

          const x3D = (avgX / width) * 10 - 5;
          const y3D = (avgY / height) * 10 - 5;

          const astronave = document.getElementById('astronave');
          astronave.setAttribute('position', `${x3D} ${y3D} -5`);
        }

        cv.drawKeypoints(gray, keypointsCurr, src);
        cv.imshow('canvasOutput', src);

        keypointsPrev.delete();
        descriptorsPrev.delete();
        keypointsPrev = keypointsCurr;
        descriptorsPrev = descriptorsCurr;

        requestAnimationFrame(processVideo);
      }

      processVideo();
    });
  }

  function onOpenCvReady() {
    console.log('OpenCV.js is ready');
    startVideoProcessing();
  }

  let Module = {
    onRuntimeInitialized: onOpenCvReady
  };
</script>

</body>
</html>
