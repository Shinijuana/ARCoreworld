<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Astronave con SLAM</title>
  
  <!-- A-Frame for rendering the scene -->
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  
  <!-- OpenCV.js library -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()" onerror="onOpenCvError()"></script>

  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #video, #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 0;
    }
    a-scene {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 1;
      overflow: hidden;
    }
    #debugCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 2;
      pointer-events: none;
    }
  </style>
</head>
<body>

<a-scene embedded 
         renderer="colorManagement: true, physicallyCorrectLights" 
         vr-mode-ui="enabled: false" 
         device-orientation-permission-ui="enabled: false">
    
  <a-assets>
      <a-asset-item id="astro" src="ASTRONAVE.glb"></a-asset-item>
  </a-assets>

  <a-entity id="astronave" position="0 0 -2" gltf-model="#astro" scale="1 1 1"></a-entity>
  <a-camera id="ar-camera" position="0 0 0" look-controls="enabled: false" class="clickable"></a-camera>
  <a-plane id="plane" position="0 0 0" rotation="-90 0 0" width="10" height="10" color="#CCC" opacity="0.5"></a-plane>
  
</a-scene>

<video id="video" autoplay></video>
<canvas id="canvas"></canvas>
<canvas id="debugCanvas"></canvas>

<script type="text/javascript">
let cvLoaded = false;
let isPlaneAnchored = false;

const anchorX = 0, anchorY = 0, anchorZ = -2;

class KalmanFilter {
  constructor(processNoise, measurementNoise, estimatedError) {
    this.processNoise = processNoise;
    this.measurementNoise = measurementNoise;
    this.estimatedError = estimatedError;
    this.posteriEstimate = 0;
    this.posteriError = 1;
  }

  update(measurement) {
    const prioriEstimate = this.posteriEstimate;
    const prioriError = this.posteriError + this.processNoise;
    const blendingFactor = prioriError / (prioriError + this.measurementNoise);
    this.posteriEstimate = prioriEstimate + blendingFactor * (measurement - prioriEstimate);
    this.posteriError = (1 - blendingFactor) * prioriError;
    return this.posteriEstimate;
  }
}

const kalmanX = new KalmanFilter(0.1, 1, 1);
const kalmanY = new KalmanFilter(0.1, 1, 1);
const kalmanZ = new KalmanFilter(0.1, 1, 1); // Add Kalman filter for Z

function onOpenCvReady() {
  cvLoaded = true;
  console.log('OpenCV.js is ready.');
  initializeApp();
}

function onOpenCvError() {
  console.error('OpenCV.js failed to load.');
}

function initializeApp() {
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const debugCanvas = document.getElementById('debugCanvas');
  const debugCtx = debugCanvas.getContext('2d');
  const ctx = canvas.getContext('2d');
  const camera = document.getElementById('ar-camera');

  let lastX = 0, lastY = 0, lastZ = 0;
  const depthScale = 1;
  const positionHistory = [];
  const maxHistoryLength = 5;

  navigator.mediaDevices.getUserMedia({ 
    video: { facingMode: "environment" }
  })
  .then((stream) => {
    video.srcObject = stream;
    video.addEventListener('loadedmetadata', () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      debugCanvas.width = canvas.width;
      debugCanvas.height = canvas.height;
      video.play();
    });
    video.addEventListener('play', () => {
      processVideo();
    });
  })
  .catch((error) => {
    console.error('Errore nell\'accesso alla fotocamera: ', error);
  });

  function detectFeatures() {
    const orb = new cv.ORB();
    const keypoints = new cv.KeyPointVector();
    const descriptors = new cv.Mat();

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    const src = cv.matFromImageData(ctx.getImageData(0, 0, canvas.width, canvas.height));
    const gray = new cv.Mat();
    const blurred = new cv.Mat();
    
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

    orb.detect(blurred, keypoints);
    
    const points = [];
    for (let i = 0; i < keypoints.size(); i++) {
      const keypoint = keypoints.get(i);
      points.push({ x: keypoint.pt.x, y: keypoint.pt.y });
    }

    src.delete();
    gray.delete();
    blurred.delete();
    keypoints.delete();
    descriptors.delete();
    
    return points;
  }

  function filterPoints(points) {
    const meanX = points.reduce((sum, p) => sum + p.x, 0) / points.length;
    const meanY = points.reduce((sum, p) => sum + p.y, 0) / points.length;

    const threshold = 50; // Threshold for outlier removal
    return points.filter(p => {
      const distance = Math.sqrt(Math.pow(p.x - meanX, 2) + Math.pow(p.y - meanY, 2));
      return distance < threshold;
    });
  }

  function estimate3DPlane(points2D) {
    if (points2D.length < 4) {
      console.error('Not enough points to estimate a plane.');
      return null;
    }

    // Convert 2D points to 3D with variable depth
    const points3D = points2D.map(p => {
      const depth = 1 + (p.y / canvas.height); // Vary depth based on Y axis
      console.log(`Point 2D: (${p.x}, ${p.y}), Depth: ${depth}`);
      return {
        x: (p.x / canvas.width) * 10 - 5,
        y: Math.max((p.y / canvas.height) * 10 - 5, 0),
        z: depth * depthScale // Variable depth
      };
    });

    // Prepare data for plane estimation
    const A = [];
    const B = [];
    points3D.forEach(p => {
      A.push([p.x, p.y, 1]);
      B.push(-p.z);
    });

    // Print data for debugging
    console.log('Matrix A:', A);
    console.log('Matrix B:', B);

    const matA = cv.matFromArray(A.length, A[0].length, cv.CV_32F, A.flat());
    const matB = cv.matFromArray(B.length, 1, cv.CV_32F, B);
    const matX = new cv.Mat();

    try {
      // Use an alternative decomposition method if RANSAC fails
      cv.solve(matA, matB, matX, cv.DECOMP_SVD);
    } catch (error) {
      console.error('Error calculating plane coefficients:', error);
      matA.delete();
      matB.delete();
      matX.delete();
      return null;
    }

    const planeCoefficients = matX.data32F;
    matA.delete();
    matB.delete();
    matX.delete();

    if (planeCoefficients.length < 3) {
      console.error('Error calculating plane coefficients. Ensure sufficient points.');
      return null;
    }

    console.log('Plane Coefficients:', planeCoefficients);

    return {
      A: planeCoefficients[0],
      B: planeCoefficients[1],
      C: 1,
      D: planeCoefficients[2]
    };
  }

  function computePlaneFromPoints(points) {
    const p1 = points[0], p2 = points[1], p3 = points[2];
    const v1 = { x: p2.x - p1.x, y: p2.y - p1.y, z: p2.z - p1.z };
    const v2 = { x: p3.x - p1.x, y: p3.y - p1.y, z: p3.z - p1.z };

    const A = v1.y * v2.z - v1.z * v2.y;
    const B = v1.z * v2.x - v1.x * v2.z;
    const C = v1.x * v2.y - v1.y * v2.x;
    const D = -(A * p1.x + B * p1.y + C * p1.z);

    return { A, B, C, D };
  }

  function smoothPosition(x, y, z) {
    if (positionHistory.length >= maxHistoryLength) {
      positionHistory.shift();
    }
    positionHistory.push({ x, y, z });

    const avgX = positionHistory.reduce((sum, p) => sum + p.x, 0) / positionHistory.length;
    const avgY = positionHistory.reduce((sum, p) => sum + p.y, 0) / positionHistory.length;
    const avgZ = positionHistory.reduce((sum, p) => sum + p.z, 0) / positionHistory.length;

    return { x: avgX, y: avgY, z: avgZ };
  }

  function estimateCameraPose(points) {
    if (points.length > 100) {
      const avgX = points.reduce((sum, p) => sum + p.x, 0) / points.length;
      const avgY = points.reduce((sum, p) => sum + p.y, 0) / points.length;

      const x3D = (avgX / canvas.width) * 100 - 5;
      const y3D = Math.max((avgY / canvas.height) * 100 - 5, 0);

      // Consider variability in depth
      const depth = 1 + (avgY / canvas.height);
      const z3D = depth * depthScale * 10;

      const smoothedX = kalmanX.update(x3D);
      const smoothedY = kalmanY.update(y3D);
      const smoothedZ = kalmanZ.update(z3D); // Use Kalman filter for Z

      const smoothPos = smoothPosition(smoothedX, smoothedY, smoothedZ);

      camera.setAttribute('position', `${smoothPos.x} ${Math.max(smoothPos.y, 0)} ${smoothPos.z}`);
      console.log(`Camera position updated: X=${smoothPos.x}, Y=${Math.max(smoothPos.y, 0)}, Z=${smoothPos.z}`);

      lastX = smoothPos.x;
      lastY = smoothPos.y;
      lastZ = smoothPos.z;
    } else {
      console.log("No points detected.");
    }
  }

  function anchorPlane(points, plane) {
    if (plane && !isPlaneAnchored) {
      const avgX = points.reduce((sum, p) => sum + p.x, 0) / points.length;
      const avgY = points.reduce((sum, p) => sum + p.y, 0) / points.length;

      const newX = (avgX / canvas.width) * 10 - 5;
      const newY = Math.max((avgY / canvas.height) * 10 - 5, 0);
      const newZ = 9;

      const smoothedX = kalmanX.update(newX);
      const smoothedY = kalmanY.update(newY);

      const smoothPos = smoothPosition(smoothedX, smoothedY, newZ);

      camera.setAttribute('position', `${smoothPos.x} ${Math.max(smoothPos.y, 0)} ${smoothPos.z}`);
      console.log(`Plane anchored: X=${smoothPos.x}, Y=${Math.max(smoothPos.y, 0)}, Z=${smoothPos.z}`);
      
      isPlaneAnchored = true;
    }
  }

  function processVideo() {
    if (!cvLoaded) {
      return;
    }

    const points = detectFeatures();
    const filteredPoints = filterPoints(points);
    
    const plane = estimate3DPlane(filteredPoints);

    if (!isPlaneAnchored) {
      anchorPlane(filteredPoints, plane);
    }

    estimateCameraPose(filteredPoints);

    requestAnimationFrame(processVideo);
  }
}

document.addEventListener('DOMContentLoaded', initializeApp);
</script>


</body>
</html>
