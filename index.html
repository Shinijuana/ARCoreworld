<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Astronave con SLAM</title>
  
  <!-- A-Frame for rendering the scene -->
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  
  <!-- OpenCV.js library -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()" onerror="onOpenCvError()"></script>

  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #video, #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 0;
    }
    a-scene {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 1;
      overflow: hidden;
    }
  </style>
</head>
<body style="margin: 0; overflow: hidden;">

<!-- A-Frame Scene -->
<a-scene embedded 
         renderer="colorManagement: true, physicallyCorrectLights" 
         vr-mode-ui="enabled: false" 
         device-orientation-permission-ui="enabled: false">
    
  <a-assets>
      <a-asset-item id="astro" src="ASTRONAVE.glb"></a-asset-item>
  </a-assets>

  <!-- Astronave Model at fixed position -->
  <a-entity id="astronave" position="0 0 -10" gltf-model="#astro" scale="1 1 1"></a-entity>

  <!-- Camera for AR scene -->
  <a-camera id="ar-camera" position="0 0 0" look-controls="enabled: false"></a-camera>
  
</a-scene>

<!-- Video Feed from Camera -->
<video id="video" autoplay></video>
<canvas id="canvas"></canvas>

<script type="text/javascript">
  let cvLoaded = false;

  function onOpenCvReady() {
    cvLoaded = true;
    console.log('OpenCV.js is ready.');
    initializeApp();
  }

  function onOpenCvError() {
    console.error('OpenCV.js failed to load.');
  }

  function initializeApp() {
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const camera = document.getElementById('ar-camera');

    let lastX = 0, lastY = 0, lastZ = 0;
    const smoothingFactor = 0.1;
    const depthScale = 1;

    navigator.mediaDevices.getUserMedia({ 
      video: { facingMode: true }
    })
    .then((stream) => {
      video.srcObject = stream;
      video.addEventListener('loadedmetadata', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        video.play();
      });
      video.addEventListener('play', () => {
        processVideo();
      });
    })
    .catch((error) => {
      console.error('Errore nell\'accesso alla fotocamera: ', error);
    });

    function detectFeatures() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

      const src = cv.matFromImageData(imageData);
      const gray = new cv.Mat();
      const corners = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      cv.goodFeaturesToTrack(gray, corners, 500, 0.01, 10);

      console.log(Numero di punti rilevati: ${corners.rows});

      if (corners.rows > 0) {
        const points = [];
        for (let i = 0; i < corners.rows; i++) {
          const pt = corners.row(i).data32F;
          points.push({ x: pt[0], y: pt[1] });
        }
        console.log('Punti rilevati:', points.map(p => (${p.x}, ${p.y})));
        return points;
      } else {
        console.log('Nessun punto rilevato.');
        return [];
      }

      src.delete(); gray.delete(); corners.delete();
    }

    function estimateCameraPose(points) {
      if (points.length > 0) {
        const avgX = points.reduce((sum, p) => sum + p.x, 0) / points.length;
        const avgY = points.reduce((sum, p) => sum + p.y, 0) / points.length;
        const x3D = (avgX / canvas.width) * 10 - 5;
        const y3D = (avgY / canvas.height) * 10 - 5;
        const zEstimate = depthScale;

        const smoothedX = lastX * (1 - smoothingFactor) + x3D * smoothingFactor;
        const smoothedY = lastY * (1 - smoothingFactor) + y3D * smoothingFactor;
        const smoothedZ = lastZ * (1 - smoothingFactor) + zEstimate * smoothingFactor;

        camera.setAttribute('position', ${smoothedX} ${smoothedY} ${smoothedZ});
        console.log(Posizione della camera aggiornata: X=${smoothedX}, Y=${smoothedY}, Z=${smoothedZ});
        
        lastX = smoothedX;
        lastY = smoothedY;
        lastZ = smoothedZ;
      } else {
        console.log("Nessun punto rilevato.");
      }
    }

    function estimatePlane(points) {
      if (points.length > 2) {
        let A = 0, B = 0, C = 0;
        let sumX = 0, sumY = 0;
        let sumXY = 0, sumXX = 0;

        points.forEach(p => {
          sumX += p.x;
          sumY += p.y;
          sumXY += p.x * p.y;
          sumXX += p.x * p.x;
        });

        const n = points.length;
        A = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
        B = (sumY - A * sumX) / n;
        C = -A * canvas.width / 2 + B * canvas.height / 2;

        console.log(Piano stimato: A=${A}, B=${B}, C=${C});
        return { A, B, C };
      } else {
        console.log("Non ci sono abbastanza punti per stimare un piano.");
        return null;
      }
    }

    function processVideo() {
      const points = detectFeatures();
      estimateCameraPose(points);
      estimatePlane(points);
      requestAnimationFrame(processVideo);
    }
  }
</script>

</body>
</html>
