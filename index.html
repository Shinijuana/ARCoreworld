<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Astronave con SLAM</title>
  
  <!-- A-Frame for rendering the scene -->
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  
  <!-- OpenCV.js library -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()" onerror="onOpenCvError()"></script>

  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #video, #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 0;
    }
    a-scene {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 2; /* Ensure it's above the debug canvas */
      overflow: hidden;
    }
    #debugCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 1; /* Between video and A-Frame scene */
      pointer-events: none;
    }
  </style>
</head>
<body>

<a-scene embedded 
         renderer="colorManagement: true, physicallyCorrectLights" 
         vr-mode-ui="enabled: false" 
         device-orientation-permission-ui="enabled: false">
    
  <a-assets>
      <a-asset-item id="astro" src="ASTRONAVE.glb"></a-asset-item>
  </a-assets>

  <a-entity id="astronave" position="0 0 -2" gltf-model="#astro" scale="1 1 1"></a-entity>
  <a-camera id="ar-camera" position="0 0 0" look-controls="enabled: false" class="clickable"></a-camera>
  <a-plane id="plane" position="0 0 0" rotation="-90 0 0" width="10" height="10" color="#CCC" opacity="0.5"></a-plane>
  
</a-scene>

<video id="video" autoplay></video>
<canvas id="canvas"></canvas>
<canvas id="debugCanvas"></canvas>

<script type="text/javascript">
let cvLoaded = false;
let isPlaneAnchored = false;

const anchorX = 0, anchorY = 0, anchorZ = -2;

class KalmanFilter {
  constructor(processNoise, measurementNoise, estimatedError) {
    this.processNoise = processNoise;
    this.measurementNoise = measurementNoise;
    this.estimatedError = estimatedError;
    this.posteriEstimate = 0;
    this.posteriError = 1;
  }

  update(measurement) {
    const prioriEstimate = this.posteriEstimate;
    const prioriError = this.posteriError + this.processNoise;
    const blendingFactor = prioriError / (prioriError + this.measurementNoise);
    this.posteriEstimate = prioriEstimate + blendingFactor * (measurement - prioriEstimate);
    this.posteriError = (1 - blendingFactor) * prioriError;
    return this.posteriEstimate;
  }
}

const kalmanX = new KalmanFilter(0.1, 1, 1);
const kalmanY = new KalmanFilter(0.1, 1, 1);
const kalmanZ = new KalmanFilter(0.1, 1, 1); // Add Kalman filter for Z

function onOpenCvReady() {
  cvLoaded = true;
  console.log('OpenCV.js is ready.');
  initializeApp();
}

function onOpenCvError() {
  console.error('OpenCV.js failed to load.');
}

function initializeApp() {
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const debugCanvas = document.getElementById('debugCanvas');
  const debugCtx = debugCanvas.getContext('2d');
  const ctx = canvas.getContext('2d');
  const camera = document.getElementById('ar-camera');

  let lastX = 0, lastY = 0, lastZ = 0;
  const depthScale = 1;
  const positionHistory = [];
  const maxHistoryLength = 5;

  navigator.mediaDevices.getUserMedia({ 
    video: { facingMode: "environment" }
  })
  .then((stream) => {
    video.srcObject = stream;
    video.addEventListener('loadedmetadata', () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      debugCanvas.width = canvas.width;
      debugCanvas.height = canvas.height;
      video.play();
    });
    video.addEventListener('play', () => {
      processVideo();
    });
  })
  .catch((error) => {
    console.error('Errore nell\'accesso alla fotocamera: ', error);
  });

  function detectFeatures() {
    const orb = new cv.ORB();
    const keypoints = new cv.KeyPointVector();
    const descriptors = new cv.Mat();

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    const src = cv.matFromImageData(ctx.getImageData(0, 0, canvas.width, canvas.height));
    const gray = new cv.Mat();
    const blurred = new cv.Mat();
    
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

    orb.detect(blurred, keypoints);
    
    const points = [];
    for (let i = 0; i < keypoints.size(); i++) {
      const keypoint = keypoints.get(i);
      points.push({ x: keypoint.pt.x, y: keypoint.pt.y });
    }

    src.delete();
    gray.delete();
    blurred.delete();
    keypoints.delete();
    descriptors.delete();
    
    return points;
  }

  function filterPoints(points) {
    const meanX = points.reduce((sum, p) => sum + p.x, 0) / points.length;
    const meanY = points.reduce((sum, p) => sum + p.y, 0) / points.length;

    const threshold = 50; // Threshold for outlier removal
    return points.filter(p => {
      const distance = Math.sqrt(Math.pow(p.x - meanX, 2) + Math.pow(p.y - meanY, 2));
      return distance < threshold;
    });
  }

  function estimate3DPlane(points2D) {
    if (points2D.length < 4) {
      console.error('Not enough points to estimate a plane.');
      return null;
    }

    // Convert 2D points to 3D with variable depth
    const points3D = points2D.map(p => {
      const depth = 1 + (p.y / canvas.height); // Vary depth based on Y axis
      return {
        x: (p.x / canvas.width) * 10 - 5,
        y: Math.max((p.y / canvas.height) * 10 - 5, 0),
        z: depth * depthScale // Variable depth
      };
    });

    return points3D;
  }

  function drawDebug(points, plane) {
    debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);

    // Draw points
    points.forEach(p => {
      debugCtx.beginPath();
      debugCtx.arc(p.x, p.y, 5, 0, 2 * Math.PI);
      debugCtx.fillStyle = "red";
      debugCtx.fill();
    });

    // Draw plane (as a rectangle for now, based on the first 2 points)
    if (points.length >= 4) {
      debugCtx.beginPath();
      debugCtx.moveTo(points[0].x, points[0].y);
      debugCtx.lineTo(points[1].x, points[1].y);
      debugCtx.lineTo(points[2].x, points[2].y);
      debugCtx.lineTo(points[3].x, points[3].y);
      debugCtx.closePath();
      debugCtx.strokeStyle = "blue";
      debugCtx.lineWidth = 2;
      debugCtx.stroke();
    }
  }

  function processVideo() {
    if (!cvLoaded) {
      return;
    }

    const points = detectFeatures();
    const filteredPoints = filterPoints(points);
    const plane = estimate3DPlane(filteredPoints);
    drawDebug(filteredPoints, plane);

    if (plane && plane.length >= 4) {
      const meanZ = plane.reduce((sum, p) => sum + p.z, 0) / plane.length;

      const smoothedX = kalmanX.update(plane[0].x);
      const smoothedY = kalmanY.update(plane[0].y);
      const smoothedZ = kalmanZ.update(meanZ); 

      camera.object3D.position.set(smoothedX, smoothedY, smoothedZ);
    }

    requestAnimationFrame(processVideo);
  }
}
</script>
</body>
</html>
